{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8e2b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import json\n",
    "import base64\n",
    "\n",
    "\n",
    "def read_image(file_name):\n",
    "    image = tf.io.read_file(file_name)\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize_with_pad(image, target_height=256, target_width=256)\n",
    "    return image\n",
    "\n",
    "\n",
    "img_paths = {\n",
    "    'A1': 'Y:\\Coding\\Project\\Apple\\Plant Disease Detection\\\\v1.2\\Python files\\Plant Validation Model\\Prediction\\img.png',\n",
    "    'A2': 'Y:\\Coding\\Project\\Apple\\Plant Disease Detection\\Datasets\\Apple dataset\\\\PlantDiseasesDataset\\\\train\\\\Apple___healthy\\\\a.JPG',\n",
    "}\n",
    "img_name_tensors = {name: read_image(img_path) for (name, img_path) in img_paths.items()}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e44f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "\n",
    "custom_objects = {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3c8a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels1 = ['is plant', 'not plant'] \n",
    "\n",
    "\n",
    "loaded_modela = load_model(\n",
    "    \"Y:\\Coding\\Project\\Apple\\Plant Disease Detection\\\\v1.2\\Python files\\Plant Validation Model\\PlantValiidationSavedModel.h5\",\n",
    "    custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ca68cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not plant: 62.0%\n",
      "is plant: 73.1%\n"
     ]
    }
   ],
   "source": [
    "def top_k_predictionsa(img, k=2):\n",
    "    image_batch = tf.expand_dims(img, 0)\n",
    "    predictions = loaded_modela(image_batch)\n",
    "    probs = tf.nn.softmax(predictions, axis=-1)\n",
    "    top_probs, top_idxs = tf.math.top_k(input=probs, k=k)\n",
    "    top_labels=class_labels1[top_idxs[0][0].numpy()]\n",
    "    return top_labels, top_probs[0][0]\n",
    "\n",
    "\n",
    "for (name, img_tensor) in img_name_tensors.items():\n",
    "    pred_label, pred_prob = top_k_predictionsa(img_tensor)\n",
    "    print(f'{pred_label}: {pred_prob:0.1%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5d3135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b414fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ['apple scab', 'apple rot', 'apple cedar rust', 'apple healthy']\n",
    "\n",
    "\n",
    "\n",
    "loaded_model = load_model(\n",
    "    \"Y:\\Coding\\Project\\Apple\\Plant Disease Detection\\\\v1.2\\Saved models\\SavedModelPlantDetectionMLModel3.h5\",\n",
    "    custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f101e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_predictions(img, k=3):\n",
    "    image_batch = tf.expand_dims(img, 0)\n",
    "    predictions = loaded_model(image_batch)\n",
    "    probs = tf.nn.softmax(predictions, axis=-1)\n",
    "    top_probs, top_idxs = tf.math.top_k(input=probs, k=k)\n",
    "    top_labels=class_labels[top_idxs[0][0].numpy()]\n",
    "    return top_labels, top_probs[0][0]\n",
    "\n",
    "for (name, img_tensor) in img_name_tensors.items():\n",
    "    pred_label, pred_prob = top_k_predictions(img_tensor)\n",
    "    print(f'{pred_label}: {pred_prob:0.1%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1da1e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = tf.zeros(shape=(256, 256, 3))\n",
    "\n",
    "m_steps = 20\n",
    "alphas = tf.linspace(start=0.0, stop=1.0, num=m_steps + 1)\n",
    "\n",
    "\n",
    "def interpolate_images(baseline, image, alphas):\n",
    "    alphas_x = alphas[:, tf.newaxis, tf.newaxis, tf.newaxis]\n",
    "    baseline_x = tf.expand_dims(baseline, axis=0)\n",
    "    input_x = tf.expand_dims(image, axis=0)\n",
    "    delta = input_x - baseline_x\n",
    "    images = baseline_x + alphas_x * delta\n",
    "    return images\n",
    "\n",
    "\n",
    "interpolated_images = interpolate_images(\n",
    "    baseline=baseline,\n",
    "    image=img_name_tensors['A1'],\n",
    "    alphas=alphas)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_gradients(images, target_class_idx):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(images)\n",
    "        logits = loaded_model(images)\n",
    "        probs = tf.nn.softmax(logits, axis=-1)[:, target_class_idx]\n",
    "    return tape.gradient(probs, images)\n",
    "\n",
    "\n",
    "path_gradients = compute_gradients(\n",
    "    images=interpolated_images,\n",
    "    target_class_idx=3)\n",
    "\n",
    "\n",
    "def integral_approximation(gradients):\n",
    "    # riemann_trapezoidal\n",
    "    grads = (gradients[:-1] + gradients[1:]) / tf.constant(2.0)\n",
    "    integrated_gradients = tf.math.reduce_mean(grads, axis=0)\n",
    "    return integrated_gradients\n",
    "\n",
    "\n",
    "ig = integral_approximation(\n",
    "    gradients=path_gradients)\n",
    "\n",
    "\n",
    "def integrated_gradients(baseline, image, target_class_idx, m_steps=30, batch_size=8):\n",
    "    # Generate alphas.\n",
    "    alphas = tf.linspace(start=0.0, stop=1.0, num=m_steps + 1)\n",
    "\n",
    "    # Collect gradients.\n",
    "    gradient_batches = []\n",
    "\n",
    "    # Iterate alphas range and batch computation for speed, memory efficiency, and scaling to larger m_steps.\n",
    "    for alpha in tf.range(0, len(alphas), batch_size):\n",
    "        from_ = alpha\n",
    "        to = tf.minimum(from_ + batch_size, len(alphas))\n",
    "        alpha_batch = alphas[from_:to]\n",
    "\n",
    "        gradient_batch = one_batch(baseline, image, alpha_batch, target_class_idx)\n",
    "        gradient_batches.append(gradient_batch)\n",
    "\n",
    "    # Concatenate path gradients together row-wise into single tensor.\n",
    "    total_gradients = tf.concat(gradient_batches, axis=0)\n",
    "\n",
    "    # Integral approximation through averaging gradients.\n",
    "    avg_gradients = integral_approximation(gradients=total_gradients)\n",
    "\n",
    "    # Scale integrated gradients with respect to input.\n",
    "    integrated_gradients = (image - baseline) * avg_gradients\n",
    "\n",
    "    return integrated_gradients\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def one_batch(baseline, image, alpha_batch, target_class_idx):\n",
    "    # Generate interpolated inputs between baseline and input.\n",
    "    interpolated_path_input_batch = interpolate_images(baseline=baseline, image=image, alphas=alpha_batch)\n",
    "\n",
    "    # Compute gradients between model outputs and interpolated inputs.\n",
    "    gradient_batch = compute_gradients(images=interpolated_path_input_batch, target_class_idx=target_class_idx)\n",
    "    return gradient_batch\n",
    "\n",
    "\n",
    "ig_attributions = integrated_gradients(baseline=baseline, image=img_name_tensors['A1'], target_class_idx=3, m_steps=120)\n",
    "\n",
    "ig_attributions = integrated_gradients(baseline=baseline, image=img_name_tensors['A2'], target_class_idx=3, m_steps=120)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f8154f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac21d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811889f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42319cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a2c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca34371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87429052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac439702",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_img_attributions_and_save(baseline, image, target_class_idx, m_steps=20, cmap=None, overlay_alpha=0.4, save_path=None):\n",
    "    attributions = integrated_gradients(baseline=baseline, image=image, target_class_idx=target_class_idx,\n",
    "                                        m_steps=m_steps)\n",
    "    save_path1 = '.\\overlay_image.png'\n",
    "\n",
    "    attribution_mask = tf.reduce_sum(tf.math.abs(attributions), axis=-1)\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, squeeze=False, figsize=(8, 8))\n",
    "\n",
    "    axs[0, 0].set_title('Baseline image')\n",
    "    axs[0, 0].imshow(baseline)\n",
    "    axs[0, 0].axis('off')\n",
    "    \n",
    "    axs[0, 1].set_title('Original image')\n",
    "    axs[0, 1].imshow(image)\n",
    "    axs[0, 1].axis('off')\n",
    "\n",
    "    axs[1, 0].set_title('Attribution mask')\n",
    "    axs[1, 0].imshow(attribution_mask, cmap=cmap)\n",
    "    axs[1, 0].axis('off')\n",
    "\n",
    "    axs[1, 1].set_title('Overlay')\n",
    "    axs[1, 1].imshow(attribution_mask, cmap=cmap)\n",
    "    axs[1, 1].imshow(image, alpha=overlay_alpha)\n",
    "    axs[1, 1].axis('off')\n",
    "    plt.savefig(save_path1)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        original_image_base64 = base64.b64encode(image.numpy()).decode('utf-8')\n",
    "        overlay_image_base64 = base64.b64encode(attribution_mask.numpy()).decode('utf-8')\n",
    "\n",
    "        data = {\n",
    "            'original_image': original_image_base64,\n",
    "            'overlay_image': overlay_image_base64,\n",
    "            'alpha': overlay_alpha,\n",
    "        }\n",
    "\n",
    "        with open(save_path, 'w') as json_file:\n",
    "            json.dump(data, json_file, indent=4)\n",
    "            print(f\"JSON data saved to {save_path}\")\n",
    "\n",
    "\n",
    "# Example usage with saving to JSON\n",
    "save_path = \".\\\\attributions_data.json\"\n",
    "\n",
    "_ = plot_img_attributions_and_save(image=img_name_tensors['A1'],\n",
    "                                   baseline=baseline,\n",
    "                                   target_class_idx=3,\n",
    "                                   m_steps=400,\n",
    "                                   cmap=plt.cm.inferno,\n",
    "                                   overlay_alpha=0.4,\n",
    "                                   save_path=save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828b6a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
