{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07ec1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import shap\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f01a492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "\n",
    "\n",
    "def read_image(image1):\n",
    "    # image2 = tf.io.decode_jpeg(image1, channels=3)\n",
    "    image2 = tf.image.convert_image_dtype(image1, tf.float32)\n",
    "    image3 = tf.image.resize_with_pad(image2, target_height=256, target_width=256)\n",
    "    return image3\n",
    "\n",
    "custom_objects = {'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffe203c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('./SavedModelPlantDetectionMLModel3.h5',custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10604e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Path to your local directory containing image data\n",
    "data_dir = './valid/valid/'\n",
    "\n",
    "# Get the list of all image files in the directory\n",
    "scab_images = [os.path.join(data_dir, 'Apple___Apple_scab', img) for img in os.listdir(os.path.join(data_dir, 'Apple___Apple_scab'))]\n",
    "rot_images = [os.path.join(data_dir, 'Apple___Black_rot', img) for img in os.listdir(os.path.join(data_dir, 'Apple___Black_rot'))]\n",
    "rust_images = [os.path.join(data_dir, 'Apple___Cedar_apple_rust', img) for img in os.listdir(os.path.join(data_dir, 'Apple___Cedar_apple_rust'))]\n",
    "healthy_images = [os.path.join(data_dir, 'Apple___healthy', img) for img in os.listdir(os.path.join(data_dir, 'Apple___healthy'))]\n",
    "\n",
    "# Combine images into a single list\n",
    "all_images = scab_images + rot_images + rust_images + healthy_images\n",
    "\n",
    "# Create labels for different classes\n",
    "scab_labels = [0] * len(scab_images)\n",
    "rot_labels = [1] * len(rot_images)\n",
    "rust_labels = [2] * len(rust_images)\n",
    "healthy_labels = [3] * len(healthy_images)\n",
    "\n",
    "# Combine labels into a single list\n",
    "all_labels = scab_labels + rot_labels + rust_labels + healthy_labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(all_images, all_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e665a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1554"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e5e41b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./valid/valid/Apple___healthy\\\\77b48eb5-7237-460f-8751-cfb231c917a7___RS_HL 7687.JPG'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af98e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def convert_images_to_arrays(image_paths):\n",
    "    image_arrays = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        # Read the image using OpenCV\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Convert the image to RGB format (OpenCV reads images in BGR format)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Convert the image to a NumPy array\n",
    "        image_array = np.array(image_rgb)\n",
    "\n",
    "        # Append the NumPy array to the list\n",
    "        image_arrays.append(image_array)\n",
    "    \n",
    "    image_arrays1 = np.array(image_arrays)\n",
    "    return image_arrays1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c233eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_arrays = convert_images_to_arrays(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef70523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1554"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtrain_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21099f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(xtrain_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f62a458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1554, 256, 256, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_arrays.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f45f6b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[162, 163, 194],\n",
       "        [164, 165, 196],\n",
       "        [166, 167, 198],\n",
       "        ...,\n",
       "        [160, 169, 200],\n",
       "        [160, 169, 200],\n",
       "        [160, 169, 200]],\n",
       "\n",
       "       [[162, 163, 194],\n",
       "        [164, 165, 196],\n",
       "        [166, 167, 198],\n",
       "        ...,\n",
       "        [160, 169, 200],\n",
       "        [160, 169, 200],\n",
       "        [161, 170, 201]],\n",
       "\n",
       "       [[162, 163, 194],\n",
       "        [164, 165, 196],\n",
       "        [165, 166, 197],\n",
       "        ...,\n",
       "        [160, 169, 200],\n",
       "        [161, 170, 201],\n",
       "        [161, 170, 201]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 98,  93, 123],\n",
       "        [ 94,  89, 119],\n",
       "        [ 91,  86, 116],\n",
       "        ...,\n",
       "        [118, 119, 150],\n",
       "        [120, 121, 152],\n",
       "        [140, 141, 172]],\n",
       "\n",
       "       [[ 92,  87, 117],\n",
       "        [ 92,  87, 117],\n",
       "        [ 93,  88, 118],\n",
       "        ...,\n",
       "        [126, 127, 158],\n",
       "        [134, 135, 166],\n",
       "        [108, 109, 140]],\n",
       "\n",
       "       [[ 86,  81, 111],\n",
       "        [ 91,  86, 116],\n",
       "        [ 97,  92, 122],\n",
       "        ...,\n",
       "        [114, 115, 146],\n",
       "        [127, 128, 159],\n",
       "        [119, 120, 151]]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_arrays[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "955f694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_arrays_float32 = xtrain_arrays.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00a980fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDeepExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtrain_arrays_float32\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\shap\\explainers\\_deep\\__init__.py:84\u001b[0m, in \u001b[0;36mDeepExplainer.__init__\u001b[1;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[0;32m     81\u001b[0m         framework \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m \u001b[43mTFDeep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_phase_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m PyTorchDeep(model, data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:162\u001b[0m, in \u001b[0;36mTFDeep.__init__\u001b[1;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;66;03m#if type(self.model)is tuple:\u001b[39;00m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;66;03m#    self.fModel(cnn.inputs, cnn.get_layer(theNameYouWant).outputs)\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_between_tensors(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_output\u001b[38;5;241m.\u001b[39mop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py:985\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;66;03m# Accept NumPy and scalar inputs by converting to Tensors.\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, (\n\u001b[0;32m    984\u001b[0m     tf\u001b[38;5;241m.\u001b[39mTensor, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m input_list):\n\u001b[1;32m--> 985\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_convert_numpy_or_python_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m   input_list \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[0;32m    988\u001b[0m \u001b[38;5;66;03m# Handle `mask` propagation from previous layer to current layer. Masks can\u001b[39;00m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;66;03m# be propagated explicitly via the `mask` argument, or implicitly via\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;66;03m# setting the `_keras_mask` attribute on the inputs to a Layer. Masks passed\u001b[39;00m\n\u001b[0;32m    991\u001b[0m \u001b[38;5;66;03m# explicitly take priority.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py:3299\u001b[0m, in \u001b[0;36m_convert_numpy_or_python_types\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   3297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_numpy_or_python_types\u001b[39m(x):\n\u001b[0;32m   3298\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (tf\u001b[38;5;241m.\u001b[39mTensor, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m)):\n\u001b[1;32m-> 3299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3300\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "e = shap.DeepExplainer(model, xtrain_arrays_float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74841932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
